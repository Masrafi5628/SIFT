{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'M:/Datasets/aloi_ill/png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Load images and assign labels based on folder names\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     21\u001b[0m     class_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, label)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(class_dir):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'M:/Datasets/aloi_ill/png'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.vq import vq\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset directory path\n",
    "data_dir = \"M:/Datasets/aloi_ill/png\"  # Update this to your dataset path\n",
    "# data_dir = \"M:\\SIFT\\small_data\"  # Update this to your dataset path11\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "# Load images and assign labels based on folder names\n",
    "for label in os.listdir(data_dir):\n",
    "    class_dir = os.path.join(data_dir, label)\n",
    "    if os.path.isdir(class_dir):\n",
    "        for file in os.listdir(class_dir):\n",
    "            if file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_paths.append(os.path.join(class_dir, file))\n",
    "                labels.append(int(label))  # Convert folder name to integer label\n",
    "\n",
    "# Step 1: Compute SIFT descriptors for each image\n",
    "sift = cv2.SIFT_create()\n",
    "descriptors_list = []\n",
    "valid_image_paths = []\n",
    "valid_labels = []\n",
    "\n",
    "for image_path, label in zip(image_paths, labels):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Warning: Could not load image {image_path}. Skipping.\")\n",
    "        continue  # Skip images that can't be loaded\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    if descriptors is not None and len(descriptors) > 0:\n",
    "        descriptors_list.append(descriptors)\n",
    "        valid_labels.append(label)  # Only add the label if descriptors are found\n",
    "        valid_image_paths.append(image_path)\n",
    "    else:\n",
    "        print(f\"Warning: No descriptors found for image {image_path}. Skipping.\")\n",
    "\n",
    "if len(descriptors_list) == 0:\n",
    "    raise ValueError(\"No valid SIFT descriptors found in the dataset. Ensure images have enough texture.\")\n",
    "\n",
    "# Step 2: Flatten all descriptors for clustering\n",
    "all_descriptors = np.vstack(descriptors_list)\n",
    "num_clusters = 50  # Define the number of visual words\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(all_descriptors)\n",
    "visual_words = kmeans.cluster_centers_\n",
    "\n",
    "# Compute histogram for each image based on the visual words\n",
    "def compute_histogram(descriptors, visual_words):\n",
    "    words, _ = vq(descriptors, visual_words)\n",
    "    hist, _ = np.histogram(words, bins=np.arange(len(visual_words) + 1))\n",
    "    return hist\n",
    "\n",
    "# GLAC feature extraction\n",
    "def compute_glac_features(image, patch_size=8, bins=8):\n",
    "    grad_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    magnitude = np.sqrt(grad_x ** 2 + grad_y ** 2)\n",
    "    orientation = np.arctan2(grad_y, grad_x) * (180 / np.pi) % 360\n",
    "\n",
    "    orientation_bin = np.floor(orientation / (360 / bins)).astype(np.int32)\n",
    "    h, w = image.shape\n",
    "    glac_features = []\n",
    "\n",
    "    for i in range(0, h, patch_size):\n",
    "        for j in range(0, w, patch_size):\n",
    "            patch_magnitude = magnitude[i:i + patch_size, j:j + patch_size]\n",
    "            patch_orientation_bin = orientation_bin[i:i + patch_size, j:j + patch_size]\n",
    "            hist = np.zeros((bins, bins))\n",
    "\n",
    "            for m in range(patch_magnitude.shape[0]):\n",
    "                for n in range(patch_magnitude.shape[1]):\n",
    "                    bin1 = patch_orientation_bin[m, n]\n",
    "                    for dx in range(-1, 2):\n",
    "                        for dy in range(-1, 2):\n",
    "                            x, y = m + dx, n + dy\n",
    "                            if 0 <= x < patch_magnitude.shape[0] and 0 <= y < patch_magnitude.shape[1]:\n",
    "                                bin2 = patch_orientation_bin[x, y]\n",
    "                                hist[bin1, bin2] += patch_magnitude[m, n] * patch_magnitude[x, y]\n",
    "\n",
    "            glac_features.append(hist.flatten())\n",
    "\n",
    "    return np.concatenate(glac_features)\n",
    "\n",
    "# Extract combined features\n",
    "combined_features = []\n",
    "for image_path, descriptors in zip(valid_image_paths, descriptors_list):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    glac_features = compute_glac_features(gray)\n",
    "    sift_histogram = compute_histogram(descriptors, visual_words)\n",
    "\n",
    "    combined_feature = np.concatenate([sift_histogram, glac_features])\n",
    "    combined_features.append(combined_feature)\n",
    "\n",
    "combined_features = np.array(combined_features)\n",
    "valid_labels = np.array(valid_labels)\n",
    "\n",
    "# Step 4: Train and test classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, valid_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = SVC(kernel='linear', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Optional: Visualize SIFT keypoints\n",
    "first_valid_image_path = valid_image_paths[0]\n",
    "first_img = cv2.imread(first_valid_image_path)\n",
    "gray = cv2.cvtColor(first_img, cv2.COLOR_BGR2GRAY)\n",
    "keypoints, _ = sift.detectAndCompute(gray, None)\n",
    "\n",
    "img_with_keypoints = cv2.drawKeypoints(\n",
    "    gray,\n",
    "    keypoints,\n",
    "    first_img.copy(),\n",
    "    flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(img_with_keypoints, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"SIFT Keypoints in the First Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
